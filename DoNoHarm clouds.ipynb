{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To mask images they must be 255, this doesn't refer to size ()\n",
    "#this refers to color R=255,G=255,B=255\n",
    "#then you can mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\dnh_all_nb.xlsx\") #really all words\n",
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\justbrazil_cloud.xlsx\")#justbrazil\n",
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\brazilprivate.xlsx\")#justbrazilprivate\n",
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\brazilpublic.xlsx\")#justpublic\n",
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\latam_all.xlsx\")#justlatam\n",
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\latam_private.xlsx\")#justlatamprivate\n",
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\latampublic.xlsx\")#justpubliclatam\n",
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\barriersall.xlsx\")#allbars\n",
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\latamb.xlsx\")#justlatamb\n",
    "#eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\brazil barriers.xlsx\")#justbrazil\n",
    "eoswords=pd.read_excel(r\"C:\\Users\\EybergA\\mapwords.xlsx\")#map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words21=pd.read_excel(r\"C:\\Users\\EybergA\\WCtestv12021.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopword_es = nltk.corpus.stopwords.words('spanish')\n",
    "#stopword_pt = nltk.corpus.stopwords.words('portuguese')\n",
    "#no this is for nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words =open(r'C:\\Users\\EybergA\\stop_words_ptsp.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = ' '\n",
    "stopwords = [\"nan\", \"de\", \"en\", \"la\", \"lo\", \"el\"] + list(STOPWORDS) + list(new_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the csv file \n",
    "for val in eoswords.words: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    for words in tokens: \n",
    "        comment_words = comment_words + words + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloudEOScareer = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloudEOScareer = WordCloud(width = 2500, height = 2000, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                mask=maskmap,\n",
    "                contour_width=3,\n",
    "                min_font_size = 10).generate(comment_words) #formasking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(wordcloudEOScareer, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig('zeroharm3.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('zeroharm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloudEOScareer.to_file(\"dnh.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (20, 20), facecolor = None) \n",
    "plt.imshow(wordcloudEOScareer) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() #all1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(eoswords.bars)\n",
    "stopwords.extend(stopwords)\n",
    "top_ten = fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#array is actually the colors and must be 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskmap = np.array(Image.open(r\"C:\\Users\\EybergA\\Downloads\\imageedit_4_2911381762.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_format(val):\n",
    "    if val == 247:\n",
    "        return 255\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform your mask into a new one that will work with the function:\n",
    "transformed_mask = np.ndarray((maskmap.shape[0],maskmap.shape[1]), np.int32)\n",
    "\n",
    "for i in range(len(maskmap)):\n",
    "    transformed_mask[i] = list(map(transform_format, maskmap[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(usagecom.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloudTeaching) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloudClinResearch) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ungrouping(words21, Nurse):\n",
    "    df = words21.copy(deep=True)\n",
    "    df = words21.loc[np.repeat(words21.index.values,words21[Nurse])\n",
    "               ].reset_index(drop=True)\n",
    "    df[Nurse] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ungrouping(df, Nurse):\n",
    "    df = df.copy(deep=True)\n",
    "    df = df.loc[np.repeat(df.index.values,df[Nurse])\n",
    "               ].reset_index(drop=True)\n",
    "    df[Nurse] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouping(words21,Nurse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensions_explode(df, col, sep):\n",
    "    df['id'] = df.index\n",
    "    df = df.join(pd.DataFrame(df[col].str\n",
    "        .split(sep, expand=True).stack()\n",
    "        .reset_index(level=1, drop=True)\n",
    "        ,columns=[col + ' '])\n",
    "        ).drop(col,1).rename(columns=str.strip\n",
    "        ).reset_index(drop=True)\n",
    "    df[col] = df[col].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dimensions_explode(words21,'words','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2=pd.read_excel(r\"C:\\Users\\EybergA\\WCtestv12021_fullnoout.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx=dimensions_explode(words2,'words','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx.to_csv('wordtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ungrouping(df, cnt):\n",
    "    df = df.copy(deep=True)\n",
    "    df = df.loc[np.repeat(df.index.values,df[cnt])\n",
    "               ].reset_index(drop=True)\n",
    "    df[cnt] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv('worstest2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = ' '\n",
    "stopwords = [\"nan\"] + list(STOPWORDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the csv file \n",
    "for val in dfx.words: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    for words in tokens: \n",
    "        comment_words = comment_words + words + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "briocloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(briocloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Allc=pd.read_excel(r\"C:\\Users\\EybergA\\fusiontext.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx=dimensions_explode(Allc,'words','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the csv file \n",
    "for val in Allc.Elaborate: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    for words in tokens: \n",
    "        comment_words = comment_words + words + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nursecloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                colormap='seismic',\n",
    "                collocations=False,\n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(nursecloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclouds=pd.read_excel(r\"C:\\Users\\EybergA\\execclouds.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1=dimensions_explode(exclouds,'words','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the csv file \n",
    "for val in ex1.words: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    for words in tokens: \n",
    "        comment_words = comment_words + words + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excloud1 = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                colormap='seismic',\n",
    "                collocations=False,\n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(excloud1) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm1=pd.read_excel(r\"C:\\Users\\EybergA\\pharmcloud.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm=dimensions_explode(pharm1,'words','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the csv file \n",
    "for val in pharm.words: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    for words in tokens: \n",
    "        comment_words = comment_words + words + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharmc = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                colormap='seismic',\n",
    "                collocations=False,\n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(pharmc) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys1=pd.read_excel(r\"C:\\Users\\EybergA\\physcloud.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physc1=dimensions_explode(phys1,'words','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the csv file \n",
    "for val in physc1.words: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    for words in tokens: \n",
    "        comment_words = comment_words + words + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physclouds = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                colormap='seismic',\n",
    "                collocations=False,\n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(physclouds) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
